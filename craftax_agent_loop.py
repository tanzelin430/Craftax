#!/usr/bin/env python3
"""
Craftax Agent Loop for Verl
ç®¡ç†å®Œæ•´çš„ Craftax ç¯å¢ƒäº¤äº’è¿‡ç¨‹
"""

import asyncio
import time
import numpy as np
from typing import Any, Dict, List
from uuid import uuid4

from transformers import AutoTokenizer
from omegaconf import DictConfig

from verl.experimental.agent_loop.agent_loop import AgentLoopBase, AgentLoopOutput, AgentLoopMetrics
from llm_agent_wrapper import CraftaxLLMWrapper


class CraftaxAgentLoop(AgentLoopBase):
    """
    Craftax Agent Loop
    ä½¿ç”¨ç±»çº§åˆ«ç¯å¢ƒæŒä¹…åŒ–ï¼Œå› ä¸º Verl æ¡†æ¶ä¼šä¸ºæ¯æ¬¡è¯·æ±‚åˆ›å»ºæ–°çš„å®ä¾‹
    
    è®¾è®¡æ€è·¯ï¼š
    - Verl ä¸ºæ¯æ¬¡è¯·æ±‚åˆ›å»ºæ–°çš„ Agent Loop å®ä¾‹
    - æˆ‘ä»¬åœ¨ç±»çº§åˆ«å­˜å‚¨ç¯å¢ƒçŠ¶æ€ï¼Œå®ç°è·¨å®ä¾‹çš„ç¯å¢ƒæŒä¹…åŒ–
    - æ¯ä¸ª worker/session å¯¹åº”ä¸€ä¸ªæŒä¹…çš„ç¯å¢ƒ
    """
    
    _max_episode_steps = 50  # ç±»çº§åˆ«é…ç½®
    _environments = {}  # ç±»çº§åˆ«ç¯å¢ƒå­˜å‚¨: worker_id -> {env_wrapper, current_state, current_obs, episode_step_count, episode_id}
    
    def __init__(self, config: DictConfig, server_manager, tokenizer: AutoTokenizer):
        super().__init__(config, server_manager, tokenizer)
        
        # ä»é…ç½®ä¸­è·å–åºåˆ—é•¿åº¦é™åˆ¶
        self.prompt_length = config.actor_rollout_ref.rollout.prompt_length
        self.response_length = config.actor_rollout_ref.rollout.response_length
        
        # ç¯å¢ƒç°åœ¨é€šè¿‡ messages ä¸­çš„ episode_id æ¥æ ‡è¯†ï¼Œä¸éœ€è¦å®ä¾‹çº§åˆ«çš„æ ‡è¯†
    
    @classmethod
    def init_class(cls, config: DictConfig, tokenizer: AutoTokenizer):
        """åˆå§‹åŒ–ç±»å…±äº«é…ç½®å¹¶é¢„åˆ›å»ºæ‰€æœ‰ç¯å¢ƒ"""
        if cls._class_initialized:
            return
        
        cls._class_initialized = True
        # ä»é…ç½®ä¸­è¯»å–æœ€å¤§æ­¥æ•°ï¼Œé»˜è®¤ 50
        cls._max_episode_steps = getattr(config, 'max_episode_steps', 50)
        
        # è·å–ç¯å¢ƒæ•°é‡ï¼ˆå¯¹åº” train_batch_sizeï¼‰
        num_episodes = getattr(config.data, 'num_episodes', 16)
        
        # è·å–å½“å‰è¿›ç¨‹ ID ä½œä¸º worker æ ‡è¯†
        import os
        worker_pid = os.getpid()
        
        # é¢„åˆ›å»ºæ‰€æœ‰ç¯å¢ƒï¼ˆæ¯ä¸ª worker åˆ›å»ºç›¸åŒçš„ç¯å¢ƒ IDï¼Œä½†åœ¨ä¸åŒçš„è¿›ç¨‹ç©ºé—´ä¸­ï¼‰
        print(f"ğŸš€ Worker {worker_pid}: Pre-creating {num_episodes} Craftax environments...")
        for i in range(num_episodes):
            env_id = f"env_{i}"
            cls._create_environment(env_id)
        
        print(f"âœ… Worker {worker_pid}: CraftaxAgentLoop class initialized with {num_episodes} environments, max_episode_steps={cls._max_episode_steps}")
    
    @classmethod
    def _create_environment(cls, env_id: str):
        """åˆ›å»ºå¹¶åˆå§‹åŒ–ä¸€ä¸ªæ–°ç¯å¢ƒ"""
        # åˆ›å»ºç¯å¢ƒ
        env_wrapper = CraftaxLLMWrapper(
            env_name='Craftax-Symbolic-v1',
            max_episode_steps=cls._max_episode_steps
        )
        
        # åˆå§‹åŒ–ç¯å¢ƒçŠ¶æ€
        seed = np.random.randint(0, 100000)
        current_obs, current_state = env_wrapper.reset(seed=seed)
        
        cls._environments[env_id] = {
            'env_wrapper': env_wrapper,
            'current_state': current_state,
            'current_obs': current_obs,
            'episode_step_count': 0,
            'episode_id': f"ep_{env_id}_{seed}"
        }
        
        print(f"ğŸ® Created environment {env_id} with seed {seed}")
    
    @classmethod
    def _get_environment(cls, env_id: str):
        """è·å–æŒ‡å®šçš„é¢„åˆ›å»ºç¯å¢ƒ"""
        if env_id not in cls._environments:
            print(f"âš ï¸ Environment {env_id} not found in pre-created environments, creating on-demand")
            cls._create_environment(env_id)
            
        return cls._environments[env_id]
    
    @classmethod
    def _reset_environment(cls, env_id: str):
        """é‡ç½®æŒ‡å®šç¯å¢ƒåˆ°æ–° episode"""
        env_data = cls._get_environment(env_id)
        
        # é‡ç½®ç¯å¢ƒ
        seed = np.random.randint(0, 100000)
        current_obs, current_state = env_data['env_wrapper'].reset(seed=seed)
        
        # æ›´æ–°çŠ¶æ€
        env_data['current_state'] = current_state
        env_data['current_obs'] = current_obs
        env_data['episode_step_count'] = 0
        env_data['episode_id'] = f"ep_{env_id}_{seed}"
        
        print(f"ğŸ”„ Reset environment {env_id} with seed {seed}")
    
    async def run(self, messages: List[Dict[str, Any]], sampling_params: Dict[str, Any]) -> AgentLoopOutput:
        """
        è¿è¡Œå•æ­¥ Craftax ç¯å¢ƒäº¤äº’
        
        å·¥ä½œæµç¨‹ï¼š
        1. ä» messages ä¸­æå–ç¯å¢ƒæ ‡è¯†ç¬¦
        2. è·å–å¯¹åº”çš„æŒä¹…åŒ–ç¯å¢ƒ
        3. ä½¿ç”¨å½“å‰ç¯å¢ƒè§‚å¯Ÿç”Ÿæˆ LLM å“åº”
        4. è§£æåŠ¨ä½œå¹¶æ‰§è¡Œç¯å¢ƒ step
        5. æ›´æ–°æŒä¹…åŒ–çš„ç¯å¢ƒçŠ¶æ€
        
        Args:
            messages: æ¥è‡ª dataset çš„æ¶ˆæ¯ï¼ŒåŒ…å«ç¯å¢ƒæ ‡è¯†ä¿¡æ¯
            sampling_params: LLM é‡‡æ ·å‚æ•°
            
        Returns:
            AgentLoopOutput: å•æ­¥äº¤äº’æ•°æ®
        """
        start_time = time.time()
        request_id = uuid4().hex
        
        # 1. ä» messages ä¸­æå–ç¯å¢ƒæ ‡è¯†ç¬¦
        env_id = "default_env"
        if messages and len(messages) > 0:
            initial_message = messages[0]
            if isinstance(initial_message, dict):
                # ä½¿ç”¨ episode_id ä½œä¸ºç¯å¢ƒæ ‡è¯†ï¼Œç¡®ä¿ä¸åŒ episode æœ‰ä¸åŒç¯å¢ƒ
                env_id = f"env_{initial_message.get('episode_id', 'default')}"
        
        # 2. è·å–å¯¹åº”çš„æŒä¹…åŒ–ç¯å¢ƒ
        env_data = self._get_environment(env_id)
        
        # 3. æ£€æŸ¥æ˜¯å¦éœ€è¦å¼€å§‹æ–° episodeï¼ˆå½“å‰è§‚å¯Ÿä¸º None è¡¨ç¤ºä¸Šä¸ª episode ç»“æŸäº†ï¼‰
        if env_data['current_obs'] is None:
            self._reset_environment(env_id)
            env_data = self._get_environment(env_id)  # é‡æ–°è·å–æ›´æ–°åçš„æ•°æ®
        
        # 3. è·å–å½“å‰ç¯å¢ƒè§‚å¯Ÿ
        wrapped_obs = env_data['env_wrapper'].wrap_observation(env_data['current_obs'])
        
        # 4. ç”Ÿæˆ LLM å“åº”
        prompt_list = [{"role": "user", "content": wrapped_obs}]
        formatted_text = self.tokenizer.apply_chat_template(
            prompt_list,
            tokenize=False,
            add_generation_prompt=True,
            enable_thinking=False  # è®­ç»ƒæ•ˆç‡è€ƒè™‘ï¼Œç¦ç”¨æ€è€ƒæ¨¡å¼
        )
        
        prompt_ids = self.tokenizer.encode(formatted_text, add_special_tokens=True)
        
        # LLM ç”Ÿæˆå“åº”
        response_ids = await self.server_manager.generate(
            request_id=f"{request_id}_{env_data['episode_id']}_step{env_data['episode_step_count']}",
            prompt_ids=prompt_ids,
            sampling_params=sampling_params
        )
        
        # è§£ç å“åº”
        response_text = self.tokenizer.decode(response_ids, skip_special_tokens=True)
        
        # 5. æ‰§è¡Œç¯å¢ƒäº¤äº’
        try:
            action_id = env_data['env_wrapper'].parse_llm_response(response_text)
        except Exception as e:
            print(f"âš ï¸ Action parsing failed: {e}, using default DO action")
            action_id = 5  # é»˜è®¤ DO åŠ¨ä½œ
        
        # æ‰§è¡ŒåŠ¨ä½œå¹¶æ›´æ–°æŒä¹…åŒ–çš„ç¯å¢ƒçŠ¶æ€
        new_obs, new_state, reward, done, _ = env_data['env_wrapper'].step(env_data['current_state'], action_id)
        
        # æ›´æ–°æŒä¹…åŒ–çš„ç¯å¢ƒçŠ¶æ€
        env_data['current_obs'] = new_obs
        env_data['current_state'] = new_state
        env_data['episode_step_count'] += 1
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®ç¯å¢ƒ
        if done:
            print(f"ğŸ Episode {env_data['episode_id']} finished after {env_data['episode_step_count']} steps")
            # ç¯å¢ƒç»“æŸï¼Œæ ‡è®°éœ€è¦é‡ç½®ï¼ˆä½†ä¸é”€æ¯ç¯å¢ƒï¼‰
            env_data['current_obs'] = None
            env_data['current_state'] = None
        
        # 5. åœ¨ response åé¢åŠ ä¸Šå½“å‰æ­¥éª¤çš„å¥–åŠ±ä¿¡æ¯
        reward_info = f" [Reward: {reward:.3f}]"
        reward_tokens = self.tokenizer.encode(reward_info, add_special_tokens=False)
        response_ids.extend(reward_tokens)
        
        # åˆ›å»ºå“åº”æ©ç 
        response_mask = [1] * len(response_ids)
        
        # 6. æ„å»ºæœ€ç»ˆè¾“å‡º
        # ä½¿ç”¨é…ç½®ä¸­çš„åºåˆ—é•¿åº¦é™åˆ¶
        final_prompt_ids = prompt_ids[:self.prompt_length]
        final_response_ids = response_ids[:self.response_length]
        final_response_mask = response_mask[:len(final_response_ids)]
        
        # æ„å»ºæŒ‡æ ‡
        total_time = time.time() - start_time
        metrics = {
            "generate_sequences": total_time * 0.8,  # å¤§éƒ¨åˆ†æ—¶é—´åœ¨ç”Ÿæˆ
            "tool_calls": total_time * 0.2,  # å°‘éƒ¨åˆ†æ—¶é—´åœ¨ç¯å¢ƒäº¤äº’
            "step_reward": reward,  # å½“å‰æ­¥å¥–åŠ±
            "episode_step": env_data['episode_step_count'],  # å½“å‰ episode æ­¥æ•°
            "done": done,  # æ˜¯å¦ç»“æŸ
            "action_id": action_id,  # æ‰§è¡Œçš„åŠ¨ä½œ
            "episode_id": str(env_data['episode_id']),  # episode æ ‡è¯†
            "env_id": env_id,  # ç¯å¢ƒæ ‡è¯†
        }
        
        return AgentLoopOutput(
            prompt_ids=final_prompt_ids,
            response_ids=final_response_ids,
            response_mask=final_response_mask,
            num_turns=1,  # æ¯æ¬¡åªæ‰§è¡Œä¸€æ­¥
            metrics=AgentLoopMetrics(**metrics),
        )