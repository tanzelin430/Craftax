#!/usr/bin/env python3
"""
Craftax Environment Interaction Script
ä½¿ç”¨ Qwen3-14B æ¨¡å‹ä¸ Craftax ç¯å¢ƒè¿›è¡Œäº¤äº’
"""

import os

# ç¦ç”¨flash attention
os.environ["FLASH_ATTENTION_DISABLE"] = "1"

# é…ç½®JAXæ˜¾å­˜ç®¡ç†
os.environ["XLA_PYTHON_CLIENT_PREALLOCATE"] = "false"  # ç¦ç”¨é¢„åˆ†é…
os.environ["XLA_PYTHON_CLIENT_MEM_FRACTION"] = "0.3"  # é™åˆ¶æ˜¾å­˜ä½¿ç”¨ä¸º30%
os.environ["XLA_PYTHON_CLIENT_ALLOCATOR"] = "platform"  # ä½¿ç”¨å¹³å°åˆ†é…å™¨

import jax
import jax.numpy as jnp

# é…ç½®JAXæ˜¾å­˜å¢é‡åˆ†é…
jax.config.update("jax_enable_x64", False)  # ä½¿ç”¨32ä½å‡å°‘æ˜¾å­˜
import numpy as np
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch
from typing import Dict, List, Any, Optional
from functools import partial

from llm_agent_wrapper import CraftaxLLMWrapper


class CraftaxQwenAgent:
    """
    ä½¿ç”¨ Qwen3-14B æ¨¡å‹çš„ Craftax æ™ºèƒ½ä½“
    æ”¯æŒGPUåŠ é€Ÿå’ŒçœŸæ­£çš„JAXå¹¶è¡ŒåŒ–
    """

    def __init__(
        self,
        model_path: str,
        device: str = "cuda",
        num_parallel_envs: int = 1,
        env_device: str = "auto",
    ):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä½“

        Args:
            model_path: Qwen3-14B æ¨¡å‹è·¯å¾„
            device: è®¾å¤‡ç±»å‹
        """
        self.device = device
        self.model_path = model_path
        self.num_parallel_envs = num_parallel_envs

        # æ£€æŸ¥JAXè®¾å¤‡å’ŒGPUçŠ¶æ€
        self._check_jax_gpu_setup()

        # åˆå§‹åŒ– Craftax ç¯å¢ƒåŒ…è£…å™¨
        self.env_wrapper = CraftaxLLMWrapper(
            env_name="Craftax-Symbolic-v1", max_episode_steps=500
        )

        # åˆ›å»ºå¹¶è¡Œç¯å¢ƒçš„JAXå‡½æ•°
        if self.has_gpu:
            self._setup_parallel_env_functions()

        # åˆå§‹åŒ–æ¨¡å‹å’Œtokenizer
        print(f"Loading model from {model_path}")
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_path, trust_remote_code=True, padding_side="left"
        )

        # æ·»åŠ pad_tokenå¦‚æœä¸å­˜åœ¨
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token

        self.model = AutoModelForCausalLM.from_pretrained(
            model_path,
            trust_remote_code=True,
            torch_dtype=torch.float16,
            device_map="auto",  # è‡ªåŠ¨åˆ†é…GPU
            attn_implementation="eager",  # ä½¿ç”¨eager attentioné¿å…flash-attné—®é¢˜
        )

        self.model.eval()

        print(f"Model and environment initialized successfully!")
        print(f"JAX devices: {jax.devices()}")
        print(f"Number of parallel environments: {self.num_parallel_envs}")

    def generate_response(self, prompt: str, max_new_tokens: int = 200) -> str:
        """
        ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå“åº”

        Args:
            prompt: è¾“å…¥æç¤º
            max_new_tokens: æœ€å¤§æ–°tokenæ•°

        Returns:
            ç”Ÿæˆçš„å“åº”æ–‡æœ¬
        """
        prompt_list = [{"role": "assistant", "content": prompt}]
        text = self.tokenizer.apply_chat_template(
            prompt_list,
            tokenize=False,
            add_generation_prompt=True,
            enable_thinking=False,  # Switch between thinking and non-thinking modes. Default is True. We need it to be False for training efficiency.
        )
        # print(f"text: {text}")
        # 2. å°†æ ¼å¼åŒ–åçš„ text è¿›è¡Œ tokenize
        #    æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨æ ¼å¼åŒ–å¥½çš„ text
        model_inputs = self.tokenizer([text], return_tensors="pt").to(self.device)

        # 3. ç”Ÿæˆå“åº”
        with torch.no_grad():
            outputs = self.model.generate(
                # 4. ç¡®ä¿ä¼ é€’çš„æ˜¯æ ¼å¼åŒ–åçš„ model_inputs
                **model_inputs,
                max_new_tokens=max_new_tokens,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
            )

        # è§£ç å“åº”ï¼ˆåªå–æ–°ç”Ÿæˆçš„éƒ¨åˆ†ï¼‰
        response = self.tokenizer.decode(
            outputs[0][model_inputs["input_ids"].shape[1] :], skip_special_tokens=True
        )

        return response.strip()

    def _check_jax_gpu_setup(self):
        """æ£€æŸ¥JAX GPUè®¾ç½®"""
        devices = jax.devices()
        print(f"Available JAX devices: {devices}")

        # æ£€æŸ¥æ˜¯å¦æœ‰GPU - JAX CUDAè®¾å¤‡çš„å¹³å°åç§°æ˜¯'gpu'
        gpu_devices = [d for d in devices if d.platform == "gpu"]
        if gpu_devices:
            print(f"Found {len(gpu_devices)} GPU devices: {gpu_devices}")
            self.has_gpu = True
        else:
            print("No GPU devices found, using CPU")
            self.has_gpu = False

    def _setup_parallel_env_functions(self):
        """è®¾ç½®å¹¶è¡Œç¯å¢ƒçš„JAXå‡½æ•°"""
        # è·å–åŸå§‹ç¯å¢ƒ
        from craftax.craftax_env import make_craftax_env_from_name

        self.base_env = make_craftax_env_from_name(
            "Craftax-Symbolic-v1", auto_reset=True
        )

        # ä½¿ç”¨JAXçš„vmapåˆ›å»ºå¹¶è¡Œç¯å¢ƒé‡ç½®å‡½æ•°
        @partial(jax.jit)
        def parallel_reset(rng_keys):
            """å¹¶è¡Œé‡ç½®å¤šä¸ªç¯å¢ƒ"""

            def single_reset(rng):
                return self.base_env.reset(rng, self.base_env.default_params)

            return jax.vmap(single_reset)(rng_keys)

        # ä½¿ç”¨JAXçš„vmapåˆ›å»ºå¹¶è¡Œç¯å¢ƒæ­¥è¿›å‡½æ•°
        @partial(jax.jit)
        def parallel_step(rng_keys, states, actions):
            """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªç¯å¢ƒçš„æ­¥è¿›"""

            def single_step(rng, state, action):
                return self.base_env.step(
                    rng, state, action, self.base_env.default_params
                )

            return jax.vmap(single_step)(rng_keys, states, actions)

        self.parallel_reset_fn = parallel_reset
        self.parallel_step_fn = parallel_step

        print(f"âœ… Parallel environment functions created with vmap")
        print(f"ğŸš€ JAX will automatically use GPU if available: {self.has_gpu}")

        # é¢„ç¼–è¯‘JAXå‡½æ•°ï¼Œé¿å…è¿è¡Œæ—¶ç¼–è¯‘å»¶è¿Ÿ
        self._warmup_jax_functions()

    def _warmup_jax_functions(self):
        """é¢„ç¼–è¯‘JAXå‡½æ•°ï¼Œé¿å…è¿è¡Œæ—¶ç¼–è¯‘å»¶è¿Ÿå¯¼è‡´GPUç©ºé—²"""
        print("ğŸ”¥ Warming up JAX functions to reduce runtime compilation delays...")

        # åˆ›å»ºå°æ‰¹é‡æ•°æ®ç”¨äºé¢„çƒ­
        warmup_batch_size = min(8, self.num_parallel_envs)

        # ç”Ÿæˆé¢„çƒ­ç”¨çš„éšæœºé”®
        warmup_rng = jax.random.PRNGKey(12345)
        warmup_keys = jax.random.split(warmup_rng, warmup_batch_size)

        # é¢„çƒ­resetå‡½æ•°
        print("  - Warming up parallel_reset_fn...")
        try:
            warmup_obs, warmup_states = self.parallel_reset_fn(warmup_keys)
            print(f"    âœ… Reset function warmed up with batch size {warmup_batch_size}")
        except Exception as e:
            print(f"    âš ï¸ Reset warmup failed: {e}")

        # é¢„çƒ­stepå‡½æ•°
        print("  - Warming up parallel_step_fn...")
        try:
            # åˆ›å»ºå‡çš„åŠ¨ä½œæ•°ç»„ï¼ˆå…¨éƒ¨æ˜¯noopåŠ¨ä½œï¼‰
            warmup_actions = jnp.zeros(warmup_batch_size, dtype=jnp.int32)
            warmup_step_keys = jax.random.split(warmup_rng, warmup_batch_size)

            # æ‰§è¡Œé¢„çƒ­step
            _, _, _, _, _ = self.parallel_step_fn(
                warmup_step_keys, warmup_states, warmup_actions
            )
            print(f"    âœ… Step function warmed up with batch size {warmup_batch_size}")
        except Exception as e:
            print(f"    âš ï¸ Step warmup failed: {e}")

        # é¢å¤–çš„é¢„çƒ­ï¼šè¿è¡Œå‡ ä¸ªå®Œæ•´çš„stepå¾ªç¯
        print("  - Running additional warmup cycles...")
        try:
            for warmup_cycle in range(3):
                cycle_keys = jax.random.split(warmup_rng, warmup_batch_size)
                warmup_actions = jnp.zeros(warmup_batch_size, dtype=jnp.int32)

                # æ‰§è¡Œä¸€ä¸ªå®Œæ•´çš„å¾ªç¯
                _, new_states, _, _, _ = self.parallel_step_fn(
                    cycle_keys, warmup_states, warmup_actions
                )
                warmup_states = new_states

            print(f"    âœ… Completed {3} warmup cycles")
        except Exception as e:
            print(f"    âš ï¸ Warmup cycles failed: {e}")

        print(
            "ğŸ”¥ JAX function warmup completed - should reduce GPU idle time during execution!"
        )

    def generate_batch_responses(
        self, prompts: List[str], max_new_tokens: int = 200
    ) -> List[str]:
        """
        æ‰¹é‡ç”Ÿæˆå“åº”ï¼ˆä½¿ç”¨GPUåŠ é€Ÿï¼‰

        Args:
            prompts: è¾“å…¥æç¤ºåˆ—è¡¨
            max_new_tokens: æœ€å¤§æ–°tokenæ•°

        Returns:
            ç”Ÿæˆçš„å“åº”æ–‡æœ¬åˆ—è¡¨
        """
        if not prompts:
            return []

        # å‡†å¤‡æ‰¹é‡è¾“å…¥
        batch_prompts = []
        for prompt in prompts:
            prompt_list = [{"role": "assistant", "content": prompt}]
            text = self.tokenizer.apply_chat_template(
                prompt_list,
                tokenize=False,
                add_generation_prompt=True,
                enable_thinking=False,
            )
            batch_prompts.append(text)

        # æ‰¹é‡tokenize
        model_inputs = self.tokenizer(
            batch_prompts, return_tensors="pt", padding=True, truncation=True
        ).to(self.device)

        # æ‰¹é‡ç”Ÿæˆï¼ˆGPUåŠ é€Ÿï¼‰- ä¼˜åŒ–ç”Ÿæˆå‚æ•°
        with torch.no_grad():
            outputs = self.model.generate(
                **model_inputs,
                max_new_tokens=max_new_tokens,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=self.tokenizer.pad_token_id,
                eos_token_id=self.tokenizer.eos_token_id,
                num_beams=1,  # ç¦ç”¨beam searchæé«˜é€Ÿåº¦
                use_cache=True,  # å¯ç”¨KVç¼“å­˜
            )

        # è§£ç å“åº”
        responses = []
        for i, output in enumerate(outputs):
            response = self.tokenizer.decode(
                output[model_inputs["input_ids"].shape[1] :], skip_special_tokens=True
            )
            responses.append(response.strip())

        return responses

    def _create_multi_gpu_env_functions(self):
        """ä¸ºæ¯ä¸ªGPUåˆ›å»ºç¯å¢ƒå‡½æ•°"""
        from craftax.craftax_env import make_craftax_env_from_name

        self.gpu_env_functions = {}

        for gpu_id, info in self.gpu_env_distribution.items():
            device = info["device"]
            num_envs = info["num_envs"]

            # åœ¨ç‰¹å®šGPUä¸Šåˆ›å»ºç¯å¢ƒå‡½æ•°
            with jax.default_device(device):
                base_env = make_craftax_env_from_name(
                    "Craftax-Symbolic-v1", auto_reset=True
                )

                # åˆ›å»ºè¯¥GPUçš„å¹¶è¡Œå‡½æ•°
                @partial(jax.jit, device=device)
                def gpu_parallel_reset(rng_keys):
                    def single_reset(rng):
                        return base_env.reset(rng, base_env.default_params)

                    return jax.vmap(single_reset)(rng_keys)

                @partial(jax.jit, device=device)
                def gpu_parallel_step(rng_keys, states, actions):
                    def single_step(rng, state, action):
                        return base_env.step(
                            rng, state, action, base_env.default_params
                        )

                    return jax.vmap(single_step)(rng_keys, states, actions)

                self.gpu_env_functions[gpu_id] = {
                    "reset_fn": gpu_parallel_reset,
                    "step_fn": gpu_parallel_step,
                    "num_envs": num_envs,
                }

        print(f"âœ… Created environment functions for {len(self.gpu_env_functions)} GPUs")

    def run_episode(self, max_steps: int = 100, verbose: bool = True) -> Dict[str, Any]:
        """
        è¿è¡Œä¸€ä¸ªå®Œæ•´çš„episode

        Args:
            max_steps: æœ€å¤§æ­¥æ•°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            episodeç»“æœç»Ÿè®¡
        """
        # é‡ç½®ç¯å¢ƒ
        wrapped_obs, state = self.env_wrapper.reset(seed=np.random.randint(0, 10000))

        total_reward = 0.0
        step_count = 0
        done = False

        episode_history = []

        if verbose:
            print("=" * 80)
            print("ğŸ® Starting New Craftax Episode")
            print("=" * 80)

        while not done and step_count < max_steps:
            if verbose:
                print(f"\nğŸ“ Step {step_count + 1}")
                print("-" * 40)

            # è·å–LLMå“åº” no limit on max new token
            llm_response = self.generate_response(wrapped_obs)

            if verbose:
                print(f"ğŸ¤– LLM Response: {llm_response}")

            # è§£æåŠ¨ä½œ
            action_id = self.env_wrapper.parse_llm_response(llm_response)
            action_name = self.env_wrapper.action_names[action_id]

            if verbose:
                print(f"âš¡ Action: {action_name} (ID: {action_id})")

            # æ‰§è¡ŒåŠ¨ä½œ
            wrapped_obs, state, reward, done, info = self.env_wrapper.step(
                state, action_id
            )
            wrapped_obs = self.env_wrapper.wrap_observation(wrapped_obs)
            total_reward += reward
            step_count += 1

            # è®°å½•æ­¥éª¤ä¿¡æ¯
            step_info = {
                "step": step_count,
                "action_id": action_id,
                "action_name": action_name,
                "reward": float(reward),
                "done": done,
                "llm_response": llm_response,
            }
            episode_history.append(step_info)

            if verbose:
                print(f"ğŸ’° Reward: {reward:.2f}")
                print(f"ğŸ“Š Total Reward: {total_reward:.2f}")
                if done:
                    print("âœ… Episode Complete!")

        # è¿”å›episodeç»Ÿè®¡
        episode_stats = {
            "total_reward": float(total_reward),
            "total_steps": step_count,
            "completed": done,
            "average_reward": float(total_reward / step_count)
            if step_count > 0
            else 0.0,
            "history": episode_history,
        }

        if verbose:
            print(f"\nğŸ“ˆ Episode Summary:")
            print(f"   Total Steps: {step_count}")
            print(f"   Total Reward: {total_reward:.2f}")
            print(f"   Average Reward: {episode_stats['average_reward']:.2f}")
            print(f"   Completed: {done}")

        return episode_stats

    def run_parallel_episodes_gpu(
        self, num_episodes: int = 4, max_steps_per_episode: int = 100
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨JAX vmapåœ¨GPUä¸ŠçœŸæ­£å¹¶è¡Œè¿è¡Œå¤šä¸ªepisodes

        Args:
            num_episodes: episodeæ•°é‡
            max_steps_per_episode: æ¯ä¸ªepisodeçš„æœ€å¤§æ­¥æ•°

        Returns:
            å¤šepisodeç»Ÿè®¡ç»“æœ
        """
        if num_episodes > self.num_parallel_envs:
            print(
                f"âš ï¸  Requested {num_episodes} episodes, but only {self.num_parallel_envs} parallel envs configured"
            )
            print(f"Running {self.num_parallel_envs} episodes in parallel")
            num_episodes = self.num_parallel_envs

        print(
            f"ğŸš€ Running {num_episodes} episodes in TRUE parallel on GPU using JAX vmap"
        )

        # åˆ›å»ºä¸åŒçš„éšæœºç§å­
        rng = jax.random.PRNGKey(42)
        rng_keys = jax.random.split(rng, num_episodes)

        # å¹¶è¡Œé‡ç½®æ‰€æœ‰ç¯å¢ƒ (GPUåŠ é€Ÿ)
        print("ğŸ”„ Resetting environments in parallel on GPU...")
        obs_batch, states_batch = self.parallel_reset_fn(rng_keys)

        # å°†JAXè§‚å¯Ÿè½¬æ¢ä¸ºæ–‡æœ¬è§‚å¯Ÿ
        from craftax.craftax.renderer import render_craftax_text

        text_observations = []
        for i in range(num_episodes):
            # ä»æ‰¹æ¬¡ä¸­æå–å•ä¸ªçŠ¶æ€
            single_state = jax.tree.map(lambda x: x[i], states_batch)
            text_obs = render_craftax_text(single_state)
            wrapped_obs = self.env_wrapper.wrap_observation(text_obs)
            text_observations.append(wrapped_obs)

        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
        total_rewards = jnp.zeros(num_episodes)
        step_counts = jnp.zeros(num_episodes, dtype=jnp.int32)
        dones = jnp.zeros(num_episodes, dtype=jnp.bool_)
        episode_histories = [[] for _ in range(num_episodes)]

        # å¹¶è¡Œæ‰§è¡Œæ­¥éª¤
        for step in range(max_steps_per_episode):
            if jnp.all(dones):
                break

            print(f"ğŸ“ Parallel Step {step + 1}/{max_steps_per_episode}")

            # æ”¶é›†æœªå®Œæˆç¯å¢ƒçš„è§‚å¯Ÿ
            active_indices = jnp.where(~dones)[0]
            if len(active_indices) == 0:
                break

            active_observations = [text_observations[i] for i in active_indices]

            # æ‰¹é‡ç”ŸæˆLLMå“åº” (GPUåŠ é€Ÿ) - æ€»æ˜¯ä½¿ç”¨æ‰¹é‡å¤„ç†
            print("â±ï¸  [GPU COMPUTE START] Batch LLM inference...")
            llm_responses = self.generate_batch_responses(active_observations)
            print("â±ï¸  [GPU COMPUTE END] Batch LLM inference completed")

            # è§£æåŠ¨ä½œ
            actions = []
            for i, response in enumerate(llm_responses):
                try:
                    action_id = self.env_wrapper.parse_llm_response(response)
                    actions.append(action_id)
                except:
                    actions.append(0)  # é»˜è®¤åŠ¨ä½œ

            # ä¸ºå¹¶è¡Œæ‰§è¡Œå‡†å¤‡åŠ¨ä½œæ•°ç»„
            action_array = jnp.zeros(num_episodes, dtype=jnp.int32)
            for i, active_idx in enumerate(active_indices):
                action_array = action_array.at[active_idx].set(actions[i])

            # åˆ›å»ºæ–°çš„éšæœºé”®
            step_rng = jax.random.split(rng, num_episodes)

            # å¹¶è¡Œæ‰§è¡Œç¯å¢ƒæ­¥éª¤ (GPUåŠ é€Ÿ)
            print("â±ï¸  [GPU COMPUTE START] Parallel environment step...")
            (
                new_obs_batch,
                new_states_batch,
                rewards_batch,
                new_dones_batch,
                info_batch,
            ) = self.parallel_step_fn(step_rng, states_batch, action_array)
            print("â±ï¸  [GPU COMPUTE END] Parallel environment step completed")

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            # åªæ›´æ–°æœªå®Œæˆçš„ç¯å¢ƒ
            mask = ~dones
            total_rewards = jnp.where(
                mask, total_rewards + rewards_batch, total_rewards
            )
            step_counts = jnp.where(mask, step_counts + 1, step_counts)
            dones = jnp.where(mask, new_dones_batch, dones)

            # æ›´æ–°çŠ¶æ€ - ç®€åŒ–å¤„ç†
            states_batch = new_states_batch

            # æ›´æ–°æ–‡æœ¬è§‚å¯Ÿ
            for i in range(num_episodes):
                if not dones[i]:
                    single_state = jax.tree.map(lambda x: x[i], states_batch)
                    text_obs = render_craftax_text(single_state)
                    wrapped_obs = self.env_wrapper.wrap_observation(text_obs)
                    text_observations[i] = wrapped_obs

                    # è®°å½•å†å²
                    if i < len(active_indices):
                        active_local_idx = jnp.where(active_indices == i)[0]
                        if len(active_local_idx) > 0:
                            local_idx = active_local_idx[0]
                            step_info = {
                                "step": int(step_counts[i]),
                                "action_id": int(actions[local_idx]),
                                "action_name": self.env_wrapper.action_names[
                                    actions[local_idx]
                                ],
                                "reward": float(rewards_batch[i]),
                                "done": bool(dones[i]),
                                "llm_response": llm_responses[local_idx],
                            }
                            episode_histories[i].append(step_info)

            # æ‰“å°è¿›åº¦
            active_count = jnp.sum(~dones)
            print(
                f"   Active environments: {active_count}, Avg reward: {jnp.mean(total_rewards):.2f}"
            )

        # æ„å»ºepisodeç»“æœ
        episodes = []
        for i in range(num_episodes):
            episode_stats = {
                "total_reward": float(total_rewards[i]),
                "total_steps": int(step_counts[i]),
                "completed": bool(dones[i]),
                "average_reward": float(total_rewards[i] / step_counts[i])
                if step_counts[i] > 0
                else 0.0,
                "history": episode_histories[i],
            }
            episodes.append(episode_stats)

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        overall_stats = {
            "num_episodes": num_episodes,
            "episodes": episodes,
            "mean_reward": float(jnp.mean(total_rewards)),
            "std_reward": float(jnp.std(total_rewards)),
            "max_reward": float(jnp.max(total_rewards)),
            "min_reward": float(jnp.min(total_rewards)),
            "completion_rate": float(jnp.mean(dones)),
        }

        print(f"\n{'='*60}")
        print("ğŸ¯ GPU PARALLEL EXECUTION RESULTS")
        print("=" * 60)
        print(f"Episodes: {num_episodes}")
        print(
            f"Mean Reward: {overall_stats['mean_reward']:.2f} Â± {overall_stats['std_reward']:.2f}"
        )
        print(f"Max Reward: {overall_stats['max_reward']:.2f}")
        print(f"Min Reward: {overall_stats['min_reward']:.2f}")
        print(f"Completion Rate: {overall_stats['completion_rate']:.1%}")

        return overall_stats

    def run_multiple_episodes(
        self, num_episodes: int = 5, max_steps_per_episode: int = 100
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå¤šä¸ªepisodes

        Args:
            num_episodes: episodeæ•°é‡
            max_steps_per_episode: æ¯ä¸ªepisodeçš„æœ€å¤§æ­¥æ•°

        Returns:
            å¤šepisodeç»Ÿè®¡ç»“æœ
        """
        all_episodes = []
        total_rewards = []

        print(f"ğŸš€ Running {num_episodes} episodes...")

        for episode_idx in range(num_episodes):
            print(f"\n{'='*60}")
            print(f"Episode {episode_idx + 1}/{num_episodes}")
            print("=" * 60)

            episode_stats = self.run_episode(
                max_steps=max_steps_per_episode, verbose=True
            )

            all_episodes.append(episode_stats)
            total_rewards.append(episode_stats["total_reward"])

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        overall_stats = {
            "num_episodes": num_episodes,
            "episodes": all_episodes,
            "mean_reward": float(np.mean(total_rewards)),
            "std_reward": float(np.std(total_rewards)),
            "max_reward": float(np.max(total_rewards)),
            "min_reward": float(np.min(total_rewards)),
            "completion_rate": float(
                sum(1 for ep in all_episodes if ep["completed"]) / num_episodes
            ),
        }

        print(f"\n{'='*60}")
        print("ğŸ“Š OVERALL STATISTICS")
        print("=" * 60)
        print(f"Episodes: {num_episodes}")
        print(
            f"Mean Reward: {overall_stats['mean_reward']:.2f} Â± {overall_stats['std_reward']:.2f}"
        )
        print(f"Max Reward: {overall_stats['max_reward']:.2f}")
        print(f"Min Reward: {overall_stats['min_reward']:.2f}")
        print(f"Completion Rate: {overall_stats['completion_rate']:.1%}")

        return overall_stats


def main():
    """ä¸»å‡½æ•°"""
    # æ¨¡å‹è·¯å¾„
    model_path = "/fs-computility/mabasic/shared/models/Qwen3-4B"

    # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ Model path not found: {model_path}")
        print("Please check the model path and try again.")
        return

    try:
        # åˆ›å»ºæ™ºèƒ½ä½“ï¼ˆæ”¯æŒå¹¶è¡Œç¯å¢ƒï¼‰
        agent = CraftaxQwenAgent(model_path=model_path, num_parallel_envs=20)  # å¹¶è¡Œ4ä¸ªç¯å¢ƒ

        # è¿è¡Œå¤šGPUå¹¶è¡Œepisodes
        results = agent.run_parallel_episodes_gpu(
            num_episodes=20, max_steps_per_episode=20
        )

        # ä¿å­˜ç»“æœ
        import json

        # è½¬æ¢JAXæ•°ç»„ä¸ºPythonåŸç”Ÿç±»å‹ä»¥ä¾¿JSONåºåˆ—åŒ–
        def convert_jax_arrays(obj):
            """é€’å½’è½¬æ¢JAXæ•°ç»„ä¸ºPythonåŸç”Ÿç±»å‹"""
            if isinstance(obj, dict):
                return {key: convert_jax_arrays(value) for key, value in obj.items()}
            elif isinstance(obj, list):
                return [convert_jax_arrays(item) for item in obj]
            elif hasattr(obj, "__array__"):  # JAXæ•°ç»„æˆ–numpyæ•°ç»„
                try:
                    return obj.tolist() if hasattr(obj, "tolist") else float(obj)
                except:
                    return str(obj)
            elif isinstance(obj, (np.integer, np.floating)):
                return obj.item()
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            else:
                return obj

        # è½¬æ¢ç»“æœ
        serializable_results = convert_jax_arrays(results)

        with open("craftax_experiment_results_4B_LT.json", "w") as f:
            json.dump(serializable_results, f, indent=2)

        print(f"\nâœ… Results saved to craftax_experiment_results.json")

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
